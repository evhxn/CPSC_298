1. When we give a prompt to a LLM, the LLM then breaks down our prompt into smaller pieces by "tokenizing" it and uses its base of tokens to find matching patterns and thus can provide an answer. But when it comes to [rompts that involve coding  sometimes the LLM might not be accurate and provides mistakes. This is because the LLM, "temperature," can affect its performance. Creating models just for coding could definitely help since these models are tuned to understand coding prompts better. This can be used in different aspects for specific prompts (different subjects) and could alleviate inaccurate answers. 
